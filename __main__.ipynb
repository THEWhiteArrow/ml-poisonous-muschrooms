{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Tuple, List, TypedDict, cast\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGBOOK:\n",
    "\n",
    "- Obervations:\n",
    "    - There is a lot of missing values in the dataset\n",
    "    - In columns sometimes there is additional irrelevant information (like the name of the column or random gibberish)\n",
    "\n",
    "- Ideas:\n",
    "    - Why don't we try to implement a solution that would predict only for rows that have all the values, rows without one certain column, rows without two certain columns, and so on?\n",
    "    - Why don't we make models for each of the case and then compare them to the one that predicts for all rows?\n",
    "    If we use a model that would output the probability instead of the class, we could ensamble the predictions by getting the predictions from different models, comparing the probabilities vs accuracy, getting the weights and ensambling the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train = pd.read_csv('./data/train.csv')\n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Main 22:45:00 | Logger setup complete\n"
     ]
    }
   ],
   "source": [
    "def setup_logger(name: str | None = None) -> logging.Logger:\n",
    "    \"\"\"A function to setup the logger\n",
    "\n",
    "    Args:\n",
    "        name (str | None, optional): Logger name. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: Configured logger\n",
    "    \"\"\"\n",
    "\n",
    "    file_handler = logging.FileHandler(\"logs.log\", mode=\"a\")\n",
    "    stream_handler = logging.StreamHandler()\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.WARNING,\n",
    "        format=\"%(levelname)s %(name)s %(asctime)s | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "        handlers=[file_handler, stream_handler],\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(name or __name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger(\"Main\")\n",
    "logger.info(\"Logger setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:153: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:153: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "/tmp/ipykernel_189422/803267626.py:153: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  (\"numerical_column_cleaner\", numerical_column_cleaner)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class ColumnTypes(TypedDict):\n",
    "    \"\"\"\n",
    "    A class to store the features and target columns of the dataset.\n",
    "    \n",
    "    Attributes:\n",
    "    - ids: List[str]\n",
    "    - labels: List[str]\n",
    "    - numerical: List[str]\n",
    "    - categorical: List[str]\n",
    "    - targets: List[str]\n",
    "    \"\"\"\n",
    "    ids: List[str]\n",
    "    \"\"\"An array of the columns that are used as the ID of the dataset.\"\"\"\n",
    "    labels: List[str]\n",
    "    \"\"\"An array of the columns that are used as the labels of the dataset. \n",
    "    Label encoding is to be used when there is a sequential correlation between the labels.\"\"\"\n",
    "\n",
    "    numerical: List[str]\n",
    "    \"\"\"An array of the columns that are numerical in nature.\"\"\"\n",
    "    categorical: List[str]\n",
    "    \"\"\"An array of the columns that are categorical in nature.\"\"\"\n",
    "    targets: List[str]\n",
    "    \"\"\"An array of the columns that are the target of the dataset.\"\"\"\n",
    "\n",
    "def get_columns_types() -> ColumnTypes:\n",
    "    \"\"\"A function that defines the types of columns in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        ColumnTypes: ColumnTypes object that contains the columns of the dataset.\n",
    "    \"\"\"\n",
    "    return ColumnTypes(\n",
    "        ids=[\"id\"],\n",
    "        targets=[\"class\"],\n",
    "        labels=[\"gill-spacing\"],\n",
    "        numerical=[\n",
    "            \"cap-diameter\",\n",
    "            \"stem-height\",\n",
    "            \"stem-width\",\n",
    "        ],\n",
    "        categorical=[\n",
    "            \"cap-shape\", \n",
    "            \"cap-surface\", \n",
    "            \"cap-color\", \n",
    "            \"does-bruise-or-bleed\",\n",
    "            \"gill-attachment\", \n",
    "            \"gill-color\",\n",
    "            \"stem-root\",\n",
    "            \"stem-surface\",\n",
    "            \"stem-color\",\n",
    "            \"veil-type\",\n",
    "            \"veil-color\",\n",
    "            \"has-ring\",\n",
    "            \"ring-type\",\n",
    "            \"spore-print-color\",\n",
    "            \"habitat\",\n",
    "            \"season\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class ColumnSet:\n",
    "    \"\"\"A class to store the information about the features of the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    is_optional: bool\n",
    "    \"\"\"A boolean value to determine if the column list is optional.\"\"\"\n",
    "    columns: List[str]\n",
    "    \"\"\"An array of the columns that are to be used in the dataset.\"\"\"\n",
    "\n",
    "def get_column_sets() -> List[ColumnSet]:\n",
    "    \"\"\"A function that defines the possible column combinations for the dataset.\n",
    "    It will create a list of ColumnSet objects that contain the possible column combinations.\n",
    "\n",
    "    Returns:\n",
    "        List[ColumnSet]: A list of ColumnSet objects that contain the possible column combinations.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        ColumnSet(is_optional=True, columns=[\"does-bruise-or-bleed\"]),\n",
    "        ColumnSet(is_optional=False, columns=[\"stem_height\", \"stem_width\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"cap-diameter\",\"cap-shape\", \"cap-surface\", \"cap-color\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"gill-spacing\", \"gill-attachment\", \"gill-color\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"stem-root\", \"stem-surface\", \"stem-color\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"veil-type\", \"veil-color\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"has-ring\", \"ring-type\"]),\n",
    "        ColumnSet(is_optional=True, columns=[\"spore-print-color\", \"habitat\", \"season\"]),\n",
    "    ]\n",
    "\n",
    "def get_column_transformer(column_types: ColumnTypes, categorical_outliers_frequency_limit : float) -> Pipeline:\n",
    "    \"\"\"A function that creates a pipeline object that contains the transformers to be used for the columns.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: A pipeline object that contains the transformers to be used for the columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def label_encode(x: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Label encoding started\")\n",
    "        for column in x.columns:\n",
    "            x[column] = pd.Series(LabelEncoder().fit_transform(x[column])).rename(column)\n",
    "\n",
    "        logger.info(\"Label encoding complete\")\n",
    "        return x\n",
    "    \n",
    "    def clean_categorical_columns(x: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Cleaning categorical columns started\")\n",
    "        logger.info(f\"Outliers frequency limit is {categorical_outliers_frequency_limit}\")\n",
    "        for column in x.columns:\n",
    "            if column in [*column_types[\"labels\"], *column_types[\"categorical\"]]: \n",
    "                \n",
    "                value_counts = x[column].value_counts().to_frame()\n",
    "                sum_value_counts = value_counts[\"count\"].sum()\n",
    "\n",
    "                outliers = cast(pd.DataFrame, value_counts[value_counts[\"count\"] < sum_value_counts * categorical_outliers_frequency_limit]).index.to_list()\n",
    "                logger.info(f\"Outliers for column '{column}' are {outliers}\")\n",
    "                x[column] = pd.Series(x[column].apply(lambda el : el if el not in outliers else \"gibberish\")).rename(column)\n",
    "\n",
    "\n",
    "                cleaned_series = x[column]\n",
    "                x[column] = cleaned_series\n",
    "\n",
    "        logger.info(\"Cleaning categorical columns complete\")\n",
    "        return x\n",
    "    \n",
    "    def clean_numerical_columns(x: pd.DataFrame) -> pd.DataFrame:\n",
    "        logger.info(\"Cleaning numerical columns started\")\n",
    "        for column in x.columns:\n",
    "            if column in column_types[\"numerical\"]:\n",
    "                n_nans = x[column].isna().sum()\n",
    "                if n_nans > 0:\n",
    "                    logger.info(f\"Column '{column}' has {n_nans} NaNs. Filling with mean {x[column].mean()}\")\n",
    "                    x[column] = x[column].fillna(x[column].mean())\n",
    "            \n",
    "        logger.info(\"Cleaning numerical columns complete\")\n",
    "        return x\n",
    "\n",
    "\n",
    "    categorical_column_cleaner = FunctionTransformer(clean_categorical_columns,)\n",
    "    numerical_column_cleaner = FunctionTransformer(clean_numerical_columns)\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", StandardScaler(), column_types[\"numerical\"]),\n",
    "            (\"categorical\", OneHotEncoder(drop=\"first\"), column_types[\"categorical\"]),\n",
    "            (\"labels\", FunctionTransformer(label_encode), column_types[\"labels\"]),\n",
    "            (\"ids\", \"passthrough\", column_types[\"ids\"]),\n",
    "            (\"targets\", \"passthrough\", column_types[\"targets\"]),\n",
    "        ]\n",
    "    )\n",
    "    logger.info(\"Column transformer created\")\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            (\"categorical_column_cleaner\", categorical_column_cleaner),\n",
    "            (\"numerical_column_cleaner\", numerical_column_cleaner)\n",
    "            (\"column_transformer\", column_transformer),\n",
    "        ],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class ColumnCreator:\n",
    "    \"\"\"A class to store the information about the columns to be created.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns_sets: List[ColumnSet]\n",
    "    \"\"\"An array of the columns that are to be used in the dataset.\"\"\"\n",
    "    column_types: ColumnTypes\n",
    "    \"\"\"A ColumnTypes object that contains the columns of the dataset.\"\"\"\n",
    "    pipeline: Pipeline\n",
    "    \"\"\"A pipeline object that contains the transformers to be used for the columns.\"\"\"\n",
    "\n",
    "    def get_possible_columns_configs(self) -> List[List[str]]:\n",
    "        \"\"\"A function that returns the possible column configurations for the dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[List[str]]: A list of lists that contain the possible column configurations.\n",
    "        \"\"\"\n",
    "        optional_columns_sets = [column_set for column_set in self.columns_sets if column_set.is_optional]\n",
    "        mandatory_columns_sets = [column_set for column_set in self.columns_sets if not column_set.is_optional]\n",
    "\n",
    "\n",
    "\n",
    "        if len(optional_columns_sets) > 10:\n",
    "            logger.warning(f\"The number of optional columns sets is too high (more than 10) - {len(optional_columns_sets)}\")\n",
    "        else :\n",
    "            logger.info(f\"The number of optional columns sets is {len(optional_columns_sets)}\")\n",
    "        \n",
    "        bitmap = 2 ** len(optional_columns_sets) - 1\n",
    "\n",
    "        possible_columns_configs : List[List[str]] = []\n",
    "        mandatory_columns : List[str] = [column for mandatory_set in mandatory_columns_sets for column in mandatory_set.columns]\n",
    "        for i in range(1, bitmap + 1):\n",
    "            columns_config : List[List[str]] = [ *mandatory_columns]\n",
    "            for j in range(len(optional_columns_sets)):\n",
    "                if i & (1 << j):\n",
    "                    columns_config.extend(optional_columns_sets[j].columns)\n",
    "\n",
    "            possible_columns_configs.append(columns_config)\n",
    "\n",
    "        return possible_columns_configs\n",
    "    \n",
    "    def transform_columns(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"A function that transforms the columns of the dataset.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The dataset to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The transformed dataset.\n",
    "        \"\"\"\n",
    "        return self.pipeline.fit_transform(data.copy())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Main 22:46:27 | Column transformer created\n",
      "INFO Main 22:46:27 | The number of optional columns sets is 7\n",
      "INFO Main 22:46:27 | Cleaning categorical columns started\n",
      "INFO Main 22:46:27 | Outliers frequency limit is 0.01\n",
      "INFO Main 22:46:27 | Outliers for column 'cap-shape' are ['d', 'e', 'n', 'w', 't', 'g', 'y', 'r', 'a', 'u', 'z', 'l', 'i', 'k', 'h', '7 x', '3.55', 'm', '4.97', '8', '6.44', '8.3', '7.6', '17.44', '4.33', '2.82', '3.91', '6.21', '8.29', '54.78', '20.25', '3.52', '3.04', 'ring-type', '10.13', 'is p', '7.43', '0.82', '10.46', '2.77', '2.94', '12.62', '5.15', '19.04', '49.21', 'b f', '9.13', '1.66', '3.37', '7.21', '3.25', '11.12', '3 x', 'is s', '4.22', '3.6', '21.56', '6 x', '24.16', '2.85', '6.53', '19.29', '5 f', '4.3', '7.41', '2.63', '19.06']\n",
      "INFO Main 22:46:29 | Outliers for column 'cap-surface' are ['n', 'f', 'p', 'u', 'a', 'm', 'o', 'r', 'x', 'c', 'b', 'z', 'season', 'ring-type', 'class', 'does None', 'has-ring', 'does t', 'is None', '5.73', '14.04', '1.42', '8.96', '10.83', 'has h', '24.38', '2.81', '0.88', '2.11', '2.79', 'does-bruise-or-bleed', '4.93', '1.08', 'is k', '10.34', 'spore-print-color', 'spore-color', '2.92', '41.91', '12.2', 'does h', '8.01', '0.87', '9.22', '1.14', '6.49', '10.1', '2.51', '7.99', 'is y', '3.64', '3.33', '15.94', '2.7', 'does l', '4.21', 'cap-diameter', '1.43', '7.14', 'is h', '0.85', '6.57', '12.79', '6.45', '4.66', '23.18', '3.06', '16.39', 'veil-color', '11.78', '8.1', '5.07']\n",
      "INFO Main 22:46:31 | Outliers for column 'cap-color' are ['f', 'd', 's', 'a', 't', 'h', 'm', 'c', 'x', 'i', 'z', 'season', 'ring-type', 'class', '3.34', 'does-bruise-or-bleed', '11.13', '5.41', '3.11', '2.57', '17.93', '8.67', '2.7', '8.57', '11.92', '3.08', '2.82', '4.24', '25.98', '20', '7', '2.9', '6.36', '5.91', '10.56', '20.02', 'stem-surface', '20.62', '4. n', '17.19', '26.89', '9.02', '2.05', '13', '7.72', '6.76', '7.15', '12.89', '8.83', '24.75', '22.38', '1.51', '3.57', '17.94', 'does n', '4.89', '6.2', '21.53', '6.41', '4.98', '3.95', '6.59', '5.25', 'veil-color', '6.9', '10.1']\n",
      "INFO Main 22:46:33 | Outliers for column 'does-bruise-or-bleed' are ['w', 'c', 'h', 'b', 'y', 'a', 'x', 's', 'k', 'd', 'e', 'p', 'l', 'z', 'o', 'g', 'n', 'i', 'has-ring', 'r', '3.43', '4.42', '2.9', 'u']\n",
      "INFO Main 22:46:34 | Outliers for column 'gill-attachment' are ['c', 'u', 'w', 't', 'k', 'y', 'i', 'g', 'm', 'b', 'n', 'o', 'h', 'l', 'r', 'z', 'season', '3.45', '15.49', '19.65', '4.01', '8.37', '28.7', '6.32', '2.54', '2.41', '6.11', '8.47', '1.32', 'does f', '13.15', '1.37', '28.15', '7.09', '9.88', '2.67', 'has d', '5.93', '1.51', '16.27', '11.26', '2.79', 'is f', '1.48', '18.21', '13.94', '32.54', 'does-bruise-or-bleed', '4.64', '4.77', 'p p', '7.92', '8.79', 'does None', 'has f', 'ring-type', '7.86', '10.85', '20.07', '2.82', '3.91', 'does', '10.23', '6.74', '0.92', '1', 'is a', '3.71', '50.44', '11.62', '16.33']\n",
      "INFO Main 22:46:36 | Outliers for column 'gill-spacing' are ['e', 'a', 's', 'b', 'x', 't', 'p', 'g', 'k', 'h', 'l', 'y', 'r', '6.67', '0', '9.01', '2.69', '3.61', 'class', '4.8', '4.04', '3.57', 'i', 'w', '24.38', 'cap-surface', '0.73', '5.22', '3.92', '5.42', '12.27', '1', '1.6', 'n', '3.81', '4.09', '1.36', '3.24', '5.55', '5.7', '3.62', 'does f', '6.4', '1.88', '55.13']\n",
      "INFO Main 22:46:38 | Outliers for column 'gill-color' are ['l', 't', 'd', 's', 'x', 'c', 'a', 'h', 'z', 'm', 'i', 'class', 'season', 'ring-type', 'spacing', 'has-ring', '5', 'spore-print-color', '18.03', 'habitat', '18.12', 'does w', '4', '3.39', '3.45', '0.92', '6.19', '5.01', '9.46', '4.49', '3.4', '17', '10.07', '8.06', '7.59', '20.6', 'stem-root', 'does-bruise-or-bleed', '8.83', '10.21', '4.64', '6.4', 'is y', 'e y', '1.91', 'does n', '16.41', '6.41', 'veil-type', '20.44', '8.37']\n",
      "INFO Main 22:46:39 | Outliers for column 'stem-root' are ['f', 'd', 'y', 'g', 'w', 'p', 'k', 'l', 't', 'n', 'x', 'i', 'u', 'a', 'e', 'o', 'h', 'm', 'z', '5.59', '2.77', '20.01', '3.63', '10.87', '16.88', '15.69', '3.23', '1.48', '20.0', '18.06', 'spore-print-color', '3.49', '13.03', '7.15']\n",
      "INFO Main 22:46:41 | Outliers for column 'stem-surface' are ['f', 'w', 'd', 'e', 'n', 'x', 'b', 'c', 'l', 'r', 'p', 'u', 'o', 'a', 'm', 'season', '0.0', '10.48', 'z', 'does-bruise-or-bleed', '5.56', '1.59', '25.83', '3.89', '4.34', '6.58', '12.04', '5.81', '5.97', '4.41', '5.48', '5.51', 'class', 'has-ring', '13.1', '17.46', '3.68', '5.35', '7.23', '1.03', 'does None', 'does s', '7.45', 'has h', '1.94', '49.46', '19.35', '2.68', '4.74', 'spore-print-color', '10.93', '24.12', '13.94']\n",
      "INFO Main 22:46:43 | Outliers for column 'stem-color' are ['r', 'l', 'b', 'f', 's', 't', 'a', 'x', 'i', 'd', 'h', 'm', 'c', 'z', 'ring-type', 'spore-print-color', 'class', '3.13', '1.75', 'e n', '7.33', 'is n', '2.78', '23.59', '8.32', '33.52', 'is w', '26.4', '4.75', '7.84', '2.75', '8.49', '4.49', '1.41', '17.45', '3.53', '12.92', '3.98', '20.07', '7.7', '22.6', '6.31', '6.09', '3.56', '3.37', '4.62', '2.54', '39.51', '18.06', '4.33']\n",
      "INFO Main 22:46:45 | Outliers for column 'veil-type' are ['w', 'a', 'e', 'f', 'c', 'b', 'y', 'k', 'g', 'n', 's', 'd', 'h', 'i', 'p', 'r', '21.11', 't', 'is None', 'l', '5.94']\n",
      "INFO Main 22:46:46 | Outliers for column 'veil-color' are ['g', 'p', 'r', 'o', 's', 't', 'a', 'd', 'i', 'h', 'f', 'c', 'l', 'b', '8.25', '2.49', 'z', '3.32']\n",
      "INFO Main 22:46:47 | Outliers for column 'has-ring' are ['r', 'h', 'c', 's', 'l', 'p', 'g', 'z', 'e', 'x', 'm', 'y', 'd', 'o', 'k', 'n', 'f has-ring', 'i', '10.3', 'w', 'a']\n",
      "INFO Main 22:46:48 | Outliers for column 'ring-type' are ['m', 't', 'd', 'n', 'x', 'b', 'y', 's', 'k', 'a', 'h', 'w', 'u', 'c', 'o', 'ring-type', 'i', 'does f', 'season', '4', '15', '3.12', 'does-bruise-or-bleed', '11', '23.6', '1', '14', '2', 'spore-print-color', 'class', 'sp', '2.87', '8.25']\n",
      "INFO Main 22:46:49 | Outliers for column 'spore-print-color' are ['y', 's', 'c', 'f', 'e', 'a', 't', 'd', 'l', 'b', 'm', 'h', 'o', 'veil-color', 'i', 'x', '2.49', '9 None', '10 None', 'class', '2.62', 'season', '9.55', '6.36', '4.58']\n",
      "INFO Main 22:46:50 | Outliers for column 'habitat' are ['w', 'p', 'u', 'e', 's', 'n', 't', 'r', 'y', 'a', 'k', 'c', 'b', 'o', 'f', 'i', 'x', 'z', 'habitat', 'class', 'spore-print-color', 'ring-type', '8.09', '17.1', 'is w', '9.28', 'does-bruise-or-bleed', 'is h', '4', '5.56', '2.94', '10.07', '7.31', '5.62', 'cap-diameter', '3.11', '16.46', '7.37', 'veil-type', '17.38', '1.66', '6.63', '18.35', '6.75', '2.44', '3.68', '2.25']\n",
      "INFO Main 22:46:52 | Outliers for column 'season' are []\n",
      "INFO Main 22:46:52 | Cleaning categorical columns complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 2) Processing column_cleaner, total=  25.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Main 22:47:00 | Label encoding started\n",
      "INFO Main 22:47:01 | Label encoding complete\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, Xs, n_samples)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1054\u001b[0m                     \u001b[0;34m\"For a sparse output, all columns should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'e'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m column_creator \u001b[38;5;241m=\u001b[39m ColumnCreator(\n\u001b[1;32m      6\u001b[0m     columns_sets\u001b[38;5;241m=\u001b[39mcolumn_sets,\n\u001b[1;32m      7\u001b[0m     column_types\u001b[38;5;241m=\u001b[39mcolumn_types,\n\u001b[1;32m      8\u001b[0m     pipeline\u001b[38;5;241m=\u001b[39mcolumn_transformer\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m possible_columns_configs \u001b[38;5;241m=\u001b[39m column_creator\u001b[38;5;241m.\u001b[39mget_possible_columns_configs()\n\u001b[0;32m---> 11\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(transformed_data)\n",
      "Cell \u001b[0;32mIn[7], line 196\u001b[0m, in \u001b[0;36mColumnCreator.transform_columns\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_columns\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A function that transforms the columns of the dataset.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        pd.DataFrame: The transformed dataset.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/pipeline.py:543\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    541\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    548\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    549\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/compose/_column_transformer.py:944\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m--> 944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/compose/_column_transformer.py:1053\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs, n_samples)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1049\u001b[0m             check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1050\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[1;32m   1051\u001b[0m         ]\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1053\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sparse output, all columns should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe a numeric or convertible to a numeric.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39mhstack(converted_Xs)\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
     ]
    }
   ],
   "source": [
    "column_sets = get_column_sets()\n",
    "column_types = get_columns_types()\n",
    "column_transformer = get_column_transformer(column_types=column_types, categorical_outliers_frequency_limit=0.01)\n",
    "\n",
    "column_creator = ColumnCreator(\n",
    "    columns_sets=column_sets,\n",
    "    column_types=column_types,\n",
    "    pipeline=column_transformer\n",
    ")\n",
    "possible_columns_configs = column_creator.get_possible_columns_configs()\n",
    "transformed_data = column_creator.transform_columns(train)\n",
    "\n",
    "print(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = transformed_data[\"stem-root\"].value_counts().to_frame()\n",
    "outliers = cast(pd.DataFrame, yo[yo[\"count\"] < yo[\"count\"].sum() * 0.01])\n",
    "display(yo)\n",
    "yo[\"count\"].sum()\n",
    "display(outliers.index.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
